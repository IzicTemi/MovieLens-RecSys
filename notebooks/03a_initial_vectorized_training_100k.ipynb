{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import lzma\n",
    "\n",
    "with lzma.open('movie_data_movielens.xz', 'rb') as f:\n",
    "    train_movie_ratings_list, test_movie_ratings_list = pickle.load(f)\n",
    "\n",
    "with lzma.open('user_data_movielens.xz', 'rb') as f:\n",
    "    train_user_ratings_list, test_user_ratings_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-03 16:37:46--  https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 978202 (955K) [application/zip]\n",
      "Saving to: ‘ml-latest-small.zip.1’\n",
      "\n",
      "ml-latest-small.zip 100%[===================>] 955.28K   780KB/s    in 1.2s    \n",
      "\n",
      "2024-05-03 16:37:48 (780 KB/s) - ‘ml-latest-small.zip.1’ saved [978202/978202]\n",
      "\n",
      "Archive:  ml-latest-small.zip\n",
      "replace ml-latest-small/links.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "!unzip 'ml-latest-small.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ratings_df = pd.read_csv('ml-latest-small/ratings.csv')\n",
    "\n",
    "movies = ratings_df['movieId'].to_numpy(dtype=int)\n",
    "ratings = ratings_df['rating'].to_numpy(dtype=float)\n",
    "users = ratings_df['userId'].to_numpy(dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rng = np.random.default_rng(2024)\n",
    "\n",
    "userid_to_index = {}\n",
    "index_to_userid = []\n",
    "movieid_to_index = {}\n",
    "index_to_movieid = []\n",
    "train_movie_ratings_list = []\n",
    "# test_movie_ratings_list = []\n",
    "train_user_ratings_list = []\n",
    "# test_user_ratings_list = []\n",
    "# movie_ratings_list = []\n",
    "# user_ratings_list = []\n",
    "\n",
    "for (user, movie, rating) in zip(users, movies, ratings):\n",
    "  if movieid_to_index.get(movie) is not None:\n",
    "    movie_index = movieid_to_index.get(movie)\n",
    "  else:\n",
    "    movie_index = len(movieid_to_index)\n",
    "    index_to_movieid.append(movie)\n",
    "    movieid_to_index[movie] = movie_index\n",
    "    train_movie_ratings_list.append([])\n",
    "    # test_movie_ratings_list.append([])\n",
    "    # movie_ratings_list.append([])\n",
    "\n",
    "  if userid_to_index.get(user) is not None:\n",
    "    user_index = userid_to_index.get(user)\n",
    "  else:\n",
    "    user_index = len(userid_to_index)\n",
    "    index_to_userid.append(user)\n",
    "    userid_to_index[user] = user_index\n",
    "    train_user_ratings_list.append([])\n",
    "    # test_user_ratings_list.append([])\n",
    "    # user_ratings_list.append([])\n",
    "\n",
    "  # user_ratings_list[user_index].append((movie_index, rating))\n",
    "  # movie_ratings_list[movie_index].append((user_index, rating))\n",
    "\n",
    "  # if rng.uniform(0, 1) < 0.8:\n",
    "  train_user_ratings_list[user_index].append((movie_index, rating))\n",
    "  train_movie_ratings_list[movie_index].append((user_index, rating))\n",
    "  # else:\n",
    "  #   test_user_ratings_list[user_index].append((movie_index, rating))\n",
    "  #   test_movie_ratings_list[movie_index].append((user_index, rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = len(train_user_ratings_list)\n",
    "N = len(train_movie_ratings_list)\n",
    "\n",
    "user_biases = np.zeros((M))\n",
    "item_biases = np.zeros((N))\n",
    "\n",
    "# Hyperparameters\n",
    "n_epochs = 100\n",
    "lmb = 1\n",
    "gamma = 1e-3\n",
    "tau = 5e-2\n",
    "k = 5\n",
    "\n",
    "U = np.random.normal(loc=0.0, scale=1/np.sqrt(k), size=(M, k))\n",
    "V = np.random.normal(loc=0.0, scale=1/np.sqrt(k), size=(N, k))\n",
    "\n",
    "train_losses = []\n",
    "train_rmses = []\n",
    "test_losses = []\n",
    "test_rmses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ef2ee5bd604d65892abeaf88f82acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss -17571.08 train rmse 0.5816\n",
      "train loss -17538.5 train rmse 0.5811\n",
      "train loss -17508.14 train rmse 0.5807\n",
      "train loss -17479.66 train rmse 0.5802\n",
      "train loss -17452.92 train rmse 0.5799\n",
      "train loss -17427.89 train rmse 0.5795\n",
      "train loss -17404.44 train rmse 0.5792\n",
      "train loss -17382.37 train rmse 0.5788\n",
      "train loss -17361.52 train rmse 0.5785\n",
      "train loss -17341.83 train rmse 0.5782\n",
      "train loss -17323.27 train rmse 0.578\n",
      "train loss -17305.76 train rmse 0.5777\n",
      "train loss -17289.2 train rmse 0.5775\n",
      "train loss -17273.47 train rmse 0.5772\n",
      "train loss -17258.47 train rmse 0.577\n",
      "train loss -17244.13 train rmse 0.5768\n",
      "train loss -17230.38 train rmse 0.5766\n",
      "train loss -17217.17 train rmse 0.5764\n",
      "train loss -17204.45 train rmse 0.5762\n",
      "train loss -17192.18 train rmse 0.576\n",
      "train loss -17180.3 train rmse 0.5758\n",
      "train loss -17168.76 train rmse 0.5756\n",
      "train loss -17157.48 train rmse 0.5755\n",
      "train loss -17146.3 train rmse 0.5753\n",
      "train loss -17135.37 train rmse 0.5751\n",
      "train loss -17124.84 train rmse 0.5749\n",
      "train loss -17114.69 train rmse 0.5748\n",
      "train loss -17104.99 train rmse 0.5746\n",
      "train loss -17095.75 train rmse 0.5745\n",
      "train loss -17086.93 train rmse 0.5743\n",
      "train loss -17078.53 train rmse 0.5742\n",
      "train loss -17070.52 train rmse 0.574\n",
      "train loss -17062.9 train rmse 0.5739\n",
      "train loss -17055.64 train rmse 0.5738\n",
      "train loss -17048.74 train rmse 0.5737\n",
      "train loss -17042.16 train rmse 0.5736\n",
      "train loss -17035.89 train rmse 0.5735\n",
      "train loss -17029.89 train rmse 0.5734\n",
      "train loss -17024.14 train rmse 0.5733\n",
      "train loss -17018.61 train rmse 0.5732\n",
      "train loss -17013.27 train rmse 0.5731\n",
      "train loss -17008.1 train rmse 0.573\n",
      "train loss -17003.08 train rmse 0.5729\n",
      "train loss -16998.21 train rmse 0.5729\n",
      "train loss -16993.5 train rmse 0.5728\n",
      "train loss -16988.94 train rmse 0.5727\n",
      "train loss -16984.5 train rmse 0.5726\n",
      "train loss -16980.17 train rmse 0.5726\n",
      "train loss -16975.94 train rmse 0.5725\n",
      "train loss -16971.78 train rmse 0.5724\n",
      "train loss -16967.68 train rmse 0.5724\n",
      "train loss -16963.62 train rmse 0.5723\n",
      "train loss -16959.6 train rmse 0.5722\n",
      "train loss -16955.68 train rmse 0.5721\n",
      "train loss -16951.87 train rmse 0.5721\n",
      "train loss -16948.2 train rmse 0.572\n",
      "train loss -16944.66 train rmse 0.572\n",
      "train loss -16941.24 train rmse 0.5719\n",
      "train loss -16937.96 train rmse 0.5718\n",
      "train loss -16934.79 train rmse 0.5718\n",
      "train loss -16931.73 train rmse 0.5717\n",
      "train loss -16928.73 train rmse 0.5717\n",
      "train loss -16925.66 train rmse 0.5716\n",
      "train loss -16922.31 train rmse 0.5716\n",
      "train loss -16919.07 train rmse 0.5715\n",
      "train loss -16916.09 train rmse 0.5715\n",
      "train loss -16913.26 train rmse 0.5714\n",
      "train loss -16910.55 train rmse 0.5714\n",
      "train loss -16908.0 train rmse 0.5713\n",
      "train loss -16905.56 train rmse 0.5713\n",
      "train loss -16903.2 train rmse 0.5713\n",
      "train loss -16900.9 train rmse 0.5712\n",
      "train loss -16898.63 train rmse 0.5712\n",
      "train loss -16896.4 train rmse 0.5712\n",
      "train loss -16894.17 train rmse 0.5711\n",
      "train loss -16891.94 train rmse 0.5711\n",
      "train loss -16889.69 train rmse 0.571\n",
      "train loss -16887.42 train rmse 0.571\n",
      "train loss -16885.12 train rmse 0.571\n",
      "train loss -16882.81 train rmse 0.5709\n",
      "train loss -16880.51 train rmse 0.5709\n",
      "train loss -16878.22 train rmse 0.5708\n",
      "train loss -16875.95 train rmse 0.5708\n",
      "train loss -16873.68 train rmse 0.5708\n",
      "train loss -16871.42 train rmse 0.5707\n",
      "train loss -16869.17 train rmse 0.5707\n",
      "train loss -16866.94 train rmse 0.5706\n",
      "train loss -16864.75 train rmse 0.5706\n",
      "train loss -16862.6 train rmse 0.5706\n",
      "train loss -16860.49 train rmse 0.5705\n",
      "train loss -16858.43 train rmse 0.5705\n",
      "train loss -16856.42 train rmse 0.5705\n",
      "train loss -16854.45 train rmse 0.5704\n",
      "train loss -16852.52 train rmse 0.5704\n",
      "train loss -16850.63 train rmse 0.5704\n",
      "train loss -16848.79 train rmse 0.5703\n",
      "train loss -16846.97 train rmse 0.5703\n",
      "train loss -16845.18 train rmse 0.5703\n",
      "train loss -16843.39 train rmse 0.5702\n",
      "train loss -16841.59 train rmse 0.5702\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(n_epochs)):\n",
    "    for m in range(M):\n",
    "        # Extract ratings and indices for the current user\n",
    "        ratings = train_user_ratings_list[m][:, 1]\n",
    "        indices = train_user_ratings_list[m][:, 0].astype(int)\n",
    "        \n",
    "        # Calculate user bias\n",
    "        user_bias = lmb * np.sum(ratings - np.einsum('i,ji->j', U[m], V[indices]) - item_biases[indices]) / (lmb * len(indices) + gamma)\n",
    "        user_biases[m] = user_bias\n",
    "        \n",
    "        # Calculate left and right matrices for user factor update\n",
    "        left = np.sum(np.einsum('ij,il->ijl', V[indices], V[indices]), axis=0)\n",
    "        right = np.sum(np.einsum('ji,j->ji', V[indices], ratings - user_bias - item_biases[indices]), axis=0)\n",
    "        \n",
    "        # Update user factor\n",
    "        U[m] = np.linalg.solve(lmb * left + tau * np.eye(k), lmb * right)\n",
    "\n",
    "    for n in range(N):\n",
    "        # Extract ratings and indices for the current item\n",
    "        ratings = train_movie_ratings_list[n][:, 1]\n",
    "        indices = train_movie_ratings_list[n][:, 0].astype(int)\n",
    "        \n",
    "        # Calculate item bias\n",
    "        item_bias = lmb * np.sum(ratings - np.einsum('ij,j->i', U[indices], V[n]) - user_biases[indices]) / (lmb * len(indices) + gamma)\n",
    "        item_biases[n] = item_bias\n",
    "        \n",
    "        # Calculate left and right matrices for item factor update\n",
    "        left = np.sum(np.einsum('ij,il->ijl', U[indices], U[indices]), axis=0)\n",
    "        right = np.sum(np.einsum('ji,j->ji', U[indices], ratings - user_biases[indices] - item_bias), axis=0)\n",
    "        \n",
    "        # Update item factor\n",
    "        V[n] = np.linalg.solve(lmb * left + tau * np.eye(k), lmb * right)\n",
    "\n",
    "    # Calculate training loss and RMSE\n",
    "    train_error_squared = 0\n",
    "    train_size = 0\n",
    "    for m in range(M):\n",
    "        ratings = train_user_ratings_list[m][:, 1]\n",
    "        indices = train_user_ratings_list[m][:, 0].astype(int)\n",
    "        train_error_squared += np.sum((ratings - np.einsum('i,ji->j', U[m], V[indices]) - user_biases[m] - item_biases[indices])**2)\n",
    "        train_size += len(indices)\n",
    "    \n",
    "    train_loss = -0.5 * lmb * train_error_squared - 0.5 * gamma * np.sum(user_biases**2) - 0.5 * gamma * np.sum(item_biases**2) - 0.5 * tau * (np.einsum('ij,ij->', V, V) + np.einsum('ij,ij->', U, U))\n",
    "    train_rmse = np.sqrt(1 / train_size * train_error_squared)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_rmses.append(train_rmse)\n",
    "    \n",
    "    print(f'train loss {round(train_loss, 2)} train rmse {round(train_rmse, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "applied-ml",
   "language": "python",
   "name": "applied-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
